{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Regressão em dados de NIRS (Near-Infrared Spectroscopy)\n",
    "\n",
    " ## Lidando com dados de alta dimensionalidade\n",
    "\n",
    " Faremos a predição da quantidade de amido no milho através de dados de espectroscopia de infravermelho próximo.\n",
    "\n",
    " Utilizaremos uma base de dados adaptada de [eigenvector](http://www.eigenvector.com/data/Corn/). A base conta com informações de 80 amostras de milho que foram medidas com 3 sensores NIRS entre as frequências de 1100-2498 nm, em intervalos de 2 nm. Assim, a base final conta com 2100 features, 80 amostras e 1 atributo preditivo, que no nosso caso, é a quantidade de amido.\n",
    "\n",
    " Nesta prática veremos como mesmo algorítmos sofisticados de AM podem ter uma performance insatisfatória caso um bom pré-processamento não seja aplicado.\n",
    "\n",
    " Iniciamos importando algumas bibliotecas úteis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Manipulação matricial, operações algébricas e estatísticas vetorizadas\n",
    "import pandas as pd # Leitura de dados\n",
    "from sklearn.tree import DecisionTreeRegressor  # CART\n",
    "from sklearn.preprocessing import StandardScaler # Normalização de dados\n",
    "\n",
    "np.random.seed(0) # Seed de geração de números aleatórios para garantir reproducibilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./starch_corn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Shuffle dos dados (embaralhamento)\n",
    " Uma boa prática para dados que não tem dependência temporal (ou não deveriam ter :P)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões: (80, 2101)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m5_wl1100nm</th>\n",
       "      <th>m5_wl1102nm</th>\n",
       "      <th>m5_wl1104nm</th>\n",
       "      <th>m5_wl1106nm</th>\n",
       "      <th>m5_wl1108nm</th>\n",
       "      <th>m5_wl1110nm</th>\n",
       "      <th>m5_wl1112nm</th>\n",
       "      <th>m5_wl1114nm</th>\n",
       "      <th>m5_wl1116nm</th>\n",
       "      <th>m5_wl1118nm</th>\n",
       "      <th>...</th>\n",
       "      <th>mp6_wl2482nm</th>\n",
       "      <th>mp6_wl2484nm</th>\n",
       "      <th>mp6_wl2486nm</th>\n",
       "      <th>mp6_wl2488nm</th>\n",
       "      <th>mp6_wl2490nm</th>\n",
       "      <th>mp6_wl2492nm</th>\n",
       "      <th>mp6_wl2494nm</th>\n",
       "      <th>mp6_wl2496nm</th>\n",
       "      <th>mp6_wl2498nm</th>\n",
       "      <th>starch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.046298</td>\n",
       "      <td>0.046143</td>\n",
       "      <td>0.046014</td>\n",
       "      <td>0.045938</td>\n",
       "      <td>0.045929</td>\n",
       "      <td>0.045919</td>\n",
       "      <td>0.045973</td>\n",
       "      <td>0.046115</td>\n",
       "      <td>0.046358</td>\n",
       "      <td>0.046696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692214</td>\n",
       "      <td>0.693482</td>\n",
       "      <td>0.694446</td>\n",
       "      <td>0.695209</td>\n",
       "      <td>0.695613</td>\n",
       "      <td>0.695715</td>\n",
       "      <td>0.695498</td>\n",
       "      <td>0.695084</td>\n",
       "      <td>0.694521</td>\n",
       "      <td>64.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.053283</td>\n",
       "      <td>0.053084</td>\n",
       "      <td>0.053001</td>\n",
       "      <td>0.052958</td>\n",
       "      <td>0.052980</td>\n",
       "      <td>0.052963</td>\n",
       "      <td>0.053088</td>\n",
       "      <td>0.053320</td>\n",
       "      <td>0.053633</td>\n",
       "      <td>0.054047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777386</td>\n",
       "      <td>0.778539</td>\n",
       "      <td>0.779503</td>\n",
       "      <td>0.780110</td>\n",
       "      <td>0.780486</td>\n",
       "      <td>0.780510</td>\n",
       "      <td>0.780258</td>\n",
       "      <td>0.779764</td>\n",
       "      <td>0.779079</td>\n",
       "      <td>65.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.032143</td>\n",
       "      <td>0.032039</td>\n",
       "      <td>0.031920</td>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.031851</td>\n",
       "      <td>0.031851</td>\n",
       "      <td>0.031935</td>\n",
       "      <td>0.032040</td>\n",
       "      <td>0.032261</td>\n",
       "      <td>0.032582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644735</td>\n",
       "      <td>0.645998</td>\n",
       "      <td>0.647045</td>\n",
       "      <td>0.647724</td>\n",
       "      <td>0.648107</td>\n",
       "      <td>0.648262</td>\n",
       "      <td>0.648119</td>\n",
       "      <td>0.647787</td>\n",
       "      <td>0.647291</td>\n",
       "      <td>64.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.049717</td>\n",
       "      <td>0.049573</td>\n",
       "      <td>0.049471</td>\n",
       "      <td>0.049391</td>\n",
       "      <td>0.049386</td>\n",
       "      <td>0.049382</td>\n",
       "      <td>0.049458</td>\n",
       "      <td>0.049639</td>\n",
       "      <td>0.049883</td>\n",
       "      <td>0.050283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692305</td>\n",
       "      <td>0.693519</td>\n",
       "      <td>0.694574</td>\n",
       "      <td>0.695208</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.695707</td>\n",
       "      <td>0.695484</td>\n",
       "      <td>0.695075</td>\n",
       "      <td>0.694381</td>\n",
       "      <td>65.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.062052</td>\n",
       "      <td>0.061749</td>\n",
       "      <td>0.061598</td>\n",
       "      <td>0.061485</td>\n",
       "      <td>0.061281</td>\n",
       "      <td>0.061126</td>\n",
       "      <td>0.061176</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>0.061361</td>\n",
       "      <td>0.061516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707183</td>\n",
       "      <td>0.708464</td>\n",
       "      <td>0.709389</td>\n",
       "      <td>0.710087</td>\n",
       "      <td>0.710465</td>\n",
       "      <td>0.710432</td>\n",
       "      <td>0.710324</td>\n",
       "      <td>0.709932</td>\n",
       "      <td>0.709275</td>\n",
       "      <td>65.519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    m5_wl1100nm  m5_wl1102nm  m5_wl1104nm  m5_wl1106nm  m5_wl1108nm  \\\n",
       "50     0.046298     0.046143     0.046014     0.045938     0.045929   \n",
       "27     0.053283     0.053084     0.053001     0.052958     0.052980   \n",
       "30     0.032143     0.032039     0.031920     0.031856     0.031851   \n",
       "77     0.049717     0.049573     0.049471     0.049391     0.049386   \n",
       "45     0.062052     0.061749     0.061598     0.061485     0.061281   \n",
       "\n",
       "    m5_wl1110nm  m5_wl1112nm  m5_wl1114nm  m5_wl1116nm  m5_wl1118nm  ...  \\\n",
       "50     0.045919     0.045973     0.046115     0.046358     0.046696  ...   \n",
       "27     0.052963     0.053088     0.053320     0.053633     0.054047  ...   \n",
       "30     0.031851     0.031935     0.032040     0.032261     0.032582  ...   \n",
       "77     0.049382     0.049458     0.049639     0.049883     0.050283  ...   \n",
       "45     0.061126     0.061176     0.061298     0.061361     0.061516  ...   \n",
       "\n",
       "    mp6_wl2482nm  mp6_wl2484nm  mp6_wl2486nm  mp6_wl2488nm  mp6_wl2490nm  \\\n",
       "50      0.692214      0.693482      0.694446      0.695209      0.695613   \n",
       "27      0.777386      0.778539      0.779503      0.780110      0.780486   \n",
       "30      0.644735      0.645998      0.647045      0.647724      0.648107   \n",
       "77      0.692305      0.693519      0.694574      0.695208      0.695652   \n",
       "45      0.707183      0.708464      0.709389      0.710087      0.710465   \n",
       "\n",
       "    mp6_wl2492nm  mp6_wl2494nm  mp6_wl2496nm  mp6_wl2498nm  starch  \n",
       "50      0.695715      0.695498      0.695084      0.694521  64.915  \n",
       "27      0.780510      0.780258      0.779764      0.779079  65.601  \n",
       "30      0.648262      0.648119      0.647787      0.647291  64.420  \n",
       "77      0.695707      0.695484      0.695075      0.694381  65.144  \n",
       "45      0.710432      0.710324      0.709932      0.709275  65.519  \n",
       "\n",
       "[5 rows x 2101 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle dataset\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "print('Dimensões:', data.shape)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Redefinindo os índices para garantir que o acesso aos dados ocorra como gostaríamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m5_wl1100nm</th>\n",
       "      <th>m5_wl1102nm</th>\n",
       "      <th>m5_wl1104nm</th>\n",
       "      <th>m5_wl1106nm</th>\n",
       "      <th>m5_wl1108nm</th>\n",
       "      <th>m5_wl1110nm</th>\n",
       "      <th>m5_wl1112nm</th>\n",
       "      <th>m5_wl1114nm</th>\n",
       "      <th>m5_wl1116nm</th>\n",
       "      <th>m5_wl1118nm</th>\n",
       "      <th>...</th>\n",
       "      <th>mp6_wl2482nm</th>\n",
       "      <th>mp6_wl2484nm</th>\n",
       "      <th>mp6_wl2486nm</th>\n",
       "      <th>mp6_wl2488nm</th>\n",
       "      <th>mp6_wl2490nm</th>\n",
       "      <th>mp6_wl2492nm</th>\n",
       "      <th>mp6_wl2494nm</th>\n",
       "      <th>mp6_wl2496nm</th>\n",
       "      <th>mp6_wl2498nm</th>\n",
       "      <th>starch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.046298</td>\n",
       "      <td>0.046143</td>\n",
       "      <td>0.046014</td>\n",
       "      <td>0.045938</td>\n",
       "      <td>0.045929</td>\n",
       "      <td>0.045919</td>\n",
       "      <td>0.045973</td>\n",
       "      <td>0.046115</td>\n",
       "      <td>0.046358</td>\n",
       "      <td>0.046696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692214</td>\n",
       "      <td>0.693482</td>\n",
       "      <td>0.694446</td>\n",
       "      <td>0.695209</td>\n",
       "      <td>0.695613</td>\n",
       "      <td>0.695715</td>\n",
       "      <td>0.695498</td>\n",
       "      <td>0.695084</td>\n",
       "      <td>0.694521</td>\n",
       "      <td>64.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.053283</td>\n",
       "      <td>0.053084</td>\n",
       "      <td>0.053001</td>\n",
       "      <td>0.052958</td>\n",
       "      <td>0.052980</td>\n",
       "      <td>0.052963</td>\n",
       "      <td>0.053088</td>\n",
       "      <td>0.053320</td>\n",
       "      <td>0.053633</td>\n",
       "      <td>0.054047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777386</td>\n",
       "      <td>0.778539</td>\n",
       "      <td>0.779503</td>\n",
       "      <td>0.780110</td>\n",
       "      <td>0.780486</td>\n",
       "      <td>0.780510</td>\n",
       "      <td>0.780258</td>\n",
       "      <td>0.779764</td>\n",
       "      <td>0.779079</td>\n",
       "      <td>65.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.032143</td>\n",
       "      <td>0.032039</td>\n",
       "      <td>0.031920</td>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.031851</td>\n",
       "      <td>0.031851</td>\n",
       "      <td>0.031935</td>\n",
       "      <td>0.032040</td>\n",
       "      <td>0.032261</td>\n",
       "      <td>0.032582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644735</td>\n",
       "      <td>0.645998</td>\n",
       "      <td>0.647045</td>\n",
       "      <td>0.647724</td>\n",
       "      <td>0.648107</td>\n",
       "      <td>0.648262</td>\n",
       "      <td>0.648119</td>\n",
       "      <td>0.647787</td>\n",
       "      <td>0.647291</td>\n",
       "      <td>64.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.049717</td>\n",
       "      <td>0.049573</td>\n",
       "      <td>0.049471</td>\n",
       "      <td>0.049391</td>\n",
       "      <td>0.049386</td>\n",
       "      <td>0.049382</td>\n",
       "      <td>0.049458</td>\n",
       "      <td>0.049639</td>\n",
       "      <td>0.049883</td>\n",
       "      <td>0.050283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692305</td>\n",
       "      <td>0.693519</td>\n",
       "      <td>0.694574</td>\n",
       "      <td>0.695208</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.695707</td>\n",
       "      <td>0.695484</td>\n",
       "      <td>0.695075</td>\n",
       "      <td>0.694381</td>\n",
       "      <td>65.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.062052</td>\n",
       "      <td>0.061749</td>\n",
       "      <td>0.061598</td>\n",
       "      <td>0.061485</td>\n",
       "      <td>0.061281</td>\n",
       "      <td>0.061126</td>\n",
       "      <td>0.061176</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>0.061361</td>\n",
       "      <td>0.061516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707183</td>\n",
       "      <td>0.708464</td>\n",
       "      <td>0.709389</td>\n",
       "      <td>0.710087</td>\n",
       "      <td>0.710465</td>\n",
       "      <td>0.710432</td>\n",
       "      <td>0.710324</td>\n",
       "      <td>0.709932</td>\n",
       "      <td>0.709275</td>\n",
       "      <td>65.519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   m5_wl1100nm  m5_wl1102nm  m5_wl1104nm  m5_wl1106nm  m5_wl1108nm  \\\n",
       "0     0.046298     0.046143     0.046014     0.045938     0.045929   \n",
       "1     0.053283     0.053084     0.053001     0.052958     0.052980   \n",
       "2     0.032143     0.032039     0.031920     0.031856     0.031851   \n",
       "3     0.049717     0.049573     0.049471     0.049391     0.049386   \n",
       "4     0.062052     0.061749     0.061598     0.061485     0.061281   \n",
       "\n",
       "   m5_wl1110nm  m5_wl1112nm  m5_wl1114nm  m5_wl1116nm  m5_wl1118nm  ...  \\\n",
       "0     0.045919     0.045973     0.046115     0.046358     0.046696  ...   \n",
       "1     0.052963     0.053088     0.053320     0.053633     0.054047  ...   \n",
       "2     0.031851     0.031935     0.032040     0.032261     0.032582  ...   \n",
       "3     0.049382     0.049458     0.049639     0.049883     0.050283  ...   \n",
       "4     0.061126     0.061176     0.061298     0.061361     0.061516  ...   \n",
       "\n",
       "   mp6_wl2482nm  mp6_wl2484nm  mp6_wl2486nm  mp6_wl2488nm  mp6_wl2490nm  \\\n",
       "0      0.692214      0.693482      0.694446      0.695209      0.695613   \n",
       "1      0.777386      0.778539      0.779503      0.780110      0.780486   \n",
       "2      0.644735      0.645998      0.647045      0.647724      0.648107   \n",
       "3      0.692305      0.693519      0.694574      0.695208      0.695652   \n",
       "4      0.707183      0.708464      0.709389      0.710087      0.710465   \n",
       "\n",
       "   mp6_wl2492nm  mp6_wl2494nm  mp6_wl2496nm  mp6_wl2498nm  starch  \n",
       "0      0.695715      0.695498      0.695084      0.694521  64.915  \n",
       "1      0.780510      0.780258      0.779764      0.779079  65.601  \n",
       "2      0.648262      0.648119      0.647787      0.647291  64.420  \n",
       "3      0.695707      0.695484      0.695075      0.694381  65.144  \n",
       "4      0.710432      0.710324      0.709932      0.709275  65.519  \n",
       "\n",
       "[5 rows x 2101 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset index\n",
    "data = data.reset_index(drop=True)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Separação em porções de treino e teste, treinamento de modelo e avaliação\n",
    "\n",
    " Aqui iremos fazer uma análise de performance muito simples. A ideia é separar o conjunto em porções de treino e teste. O teste nunca será utilizado para treinar o modelo, servindo apenas como indicativo de desempenho. Outras estratégia são preferíveis em situações reais para avaliação de desempenho, como por exemplo, a validação cruzada. No entanto, esse não é o nosso foco aqui. Passos a serem desenvolvidos:\n",
    "\n",
    " - Separação do conjunto em porções de treino e teste (80/20)\n",
    " - Definição de métricas de avaliação\n",
    " - Treinamento de regressor\n",
    " - Avaliação\n",
    "\n",
    " Primeiramente, tomaremos 80% das amostras para treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizaremos 64 amostras para treino!\n"
     ]
    }
   ],
   "source": [
    "threshold = int(round(0.8 * len(data)))\n",
    "print('Utilizaremos {} amostras para treino!'.format(threshold))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Partições de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões treino: (64, 2101)\n",
      "Dimensões teste: (16, 2101)\n"
     ]
    }
   ],
   "source": [
    "# Aqui estou transformando os DataFrames pandas para ndarrays\n",
    "# do numpy, tanto por desempenho quanto por conveniência\n",
    "tr = data.iloc[:threshold, :].values\n",
    "ts = data.iloc[threshold:, :].values\n",
    "\n",
    "print('Dimensões treino:', tr.shape)\n",
    "print('Dimensões teste:', ts.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Separação das features de treinamento e o atributo alvo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, y_tr = tr[:, :-1], tr[:, -1]\n",
    "X_ts, y_ts = ts[:, :-1], ts[:, -1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Antes de continuar...\n",
    "\n",
    " Como iremos avaliar nosso futuro regressor? Nos dados de teste, certo? Mas e com que métricas de avaliação? Será que algumas são mais adequadas do que as outras dependendo do contexto?\n",
    "\n",
    " Avaliaremos duas possibilidades:\n",
    " - Root Mean Square Error (RMSE)\n",
    " - Relative Root Mean Square Error (RRMSE)\n",
    "\n",
    " #### RMSE\n",
    "\n",
    " Mede a raiz do desvio quadrático da previsão ($\\hat{y}$) para os valores esperados ($y$). Os valores resultantes estão na mesma escala do que o atributo alvo.\n",
    "\n",
    " \\begin{equation*}\n",
    "     \\text{RMSE} = \\sqrt{\\frac{\\sum_{i}^{n}(y_i - \\hat{y}_i)^2}{n}}\n",
    " \\end{equation*}\n",
    "\n",
    " #### RRMSE\n",
    "\n",
    " Compara o RMSE do preditor contra um baseline (que é a média da variável alvo). Não possui escala, mas permite interpretações interessantes. Por exemplo, um $\\text{RRMSE} \\ge 1$ implica que o regressor é pior ou tão ruim quanto o baseline (sempre \"chutar\" na média).\n",
    "\n",
    " \\begin{equation*}\n",
    "     \\text{RRMSE} = \\sqrt{\\frac{\\sum_{i}^{n}(y_i - \\hat{y}_i)^2}{\\sum_{i}^{n} (y_i - \\overline{y})^2}}\n",
    " \\end{equation*}\n",
    "\n",
    " Implementações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(obs, pred):\n",
    "    return np.sqrt(np.sum((obs - pred) ** 2) / len(obs))\n",
    "\n",
    "def RRMSE(obs, pred):\n",
    "    # Adicionamos uma pequena constante (10^{-6}) no numerador e denominador\n",
    "    # para evitar possíveis divisões por zero\n",
    "    num = np.sum((obs - pred) ** 2) + 1e-6\n",
    "    den = np.sum((obs - np.mean(obs)) ** 2) + 1e-6\n",
    "    \n",
    "    return np.sqrt(num / den)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Normalizando dados e treinando uma DT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X_tr = scaler_x.fit_transform(X_tr)\n",
    "y_tr = scaler_y.fit_transform(y_tr.reshape(-1, 1))[:, 0]\n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth=4)\n",
    "dt.fit(X_tr, y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Avaliando o modelo treinado\n",
    "\n",
    " Aqui, **aplicamos** a mesma estratégia de normalização nos dados de teste antes de submetê-los ao modelo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ts = scaler_x.transform(X_ts)\n",
    "predictions_orig = dt.predict(X_ts)\n",
    "predictions_orig = scaler_y.inverse_transform(predictions_orig.reshape(-1, 1))[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64.92757143, 64.47071429, 66.472     , 64.47071429, 65.16557143,\n",
       "       65.7995    , 65.2705    , 64.92757143, 64.47071429, 64.407     ,\n",
       "       64.92757143, 65.371     , 64.47071429, 65.2705    , 64.92757143,\n",
       "       63.28366667])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " E calculamos os erros obtidos:\n",
    "\n",
    "\n",
    " #### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9979204392405914\n"
     ]
    }
   ],
   "source": [
    "print('RMSE:', RMSE(y_ts, predictions_orig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Será que estamos indo bem? Que tal olhar os ranges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range dos dados de treinamento: 4.73246234746976\n",
      "Range dos dados de teste: 2.9110000000000085\n"
     ]
    }
   ],
   "source": [
    "print('Range dos dados de treinamento:', max(y_tr) - min(y_tr))\n",
    "print('Range dos dados de teste:', max(y_ts) - min(y_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Parece que o erro aparentemente baixo não foi tão baixo assim.\n",
    "\n",
    " Agora iremos avaliar o nosso modelo na presença de um baseline:\n",
    "\n",
    " #### RRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRMSE: 1.0566776323700506\n"
     ]
    }
   ],
   "source": [
    "print('RRMSE:', RRMSE(y_ts, predictions_orig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Conclusão:\n",
    "\n",
    " ~~Teria sido melhor ir assistir o filme do Pelé.~~ Teria sido melhor sempre chutar a média do conjunto de teste. :/\n",
    "\n",
    " Mas e agora? O que fazer? Por que um modelo dito robusto e acurado se saiu tão mal?\n",
    "\n",
    " O que estamos deixando passar?\n",
    "\n",
    " #### Hipóteses:\n",
    "\n",
    " - ~~Problema de um milhão de dólares!~~ (pouco provável)\n",
    " - ~~Bug do sklearn~~ (pode acontecer, mas pouco provável nesse caso)\n",
    " - ~~Problema na pecinha atrás do computador~~ (acontece com bastante frequência, mas não é o caso dessa vez)\n",
    " - Dados? Poucas amostras para treinamento? $\\rightarrow$ pode ser um caminho...\n",
    " - Forma como tratamos os dados $\\rightarrow$ pré-processamento?\n",
    "     * Muito provável!\n",
    "\n",
    "\n",
    " Vamos voltar ao princípio, analisando os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 2101)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensões dos dados de treinamento\n",
    "tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Algo estranho?\n",
    "\n",
    " Sim!!! Temos muito mais descritores do que amostras. Uma alternativa pode ser utilizar um extrator de features, já que nesse contexto estamos mais interessados em predizer a propriedade do que interpretar os atributos que estamos utilizando para tal tarefa.\n",
    "\n",
    " Utilizaremos a Principal Component Analysis ([PCA](https://towardsdatascience.com/a-step-by-step-explanation-of-principal-component-analysis-b836fb9c97e2)) para esse fim!\n",
    "\n",
    " (peço desculpas pela más prática de programação a seguir -- importando novos pacotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # Biblioteca para a construção de gráficos\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo novos conjuntos de treinamento\n",
    "X_tr_pca = tr[:, :-1]\n",
    "X_ts_pca = ts[:, :-1]\n",
    "\n",
    "scaler_x_pca = StandardScaler()\n",
    "X_tr_pca = scaler_x_pca.fit_transform(X_tr_pca)\n",
    "X_ts_pca = scaler_x_pca.transform(X_ts_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Vamos fazer alguns testes com a PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Começamos chutando alto => n_components == número de amostras (máximo permitido pelo sklearn)\n",
    "pca = PCA()\n",
    "pca.fit(X_tr_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Antes de utilizarmos tantos componentes, que tal avaliarmos a **variância dos dados** que cada um deles explica (em %)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot([i + 1 for i in range(len(pca.explained_variance_ratio_))], 100 * pca.explained_variance_ratio_, 'b-')\n",
    "ax.set_xlabel('Componentes')\n",
    "ax.set_ylabel('% da variância explicada')\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Parece haver uma queda vertiginosa! Vamos explorar do ponto de vista cumulativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiros elementos [96.71311686 98.36254659 99.32135205 99.56146196 99.76429908 99.86628713\n",
      " 99.90018263 99.93236289 99.95569175 99.96827882 99.97993207 99.98720371\n",
      " 99.99008989 99.99256241 99.99399365 99.995182   99.99602121 99.99670565\n",
      " 99.99723513 99.99762539]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Primeiros elementos', (100 * pca.explained_variance_ratio_.cumsum())[:20])\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot([i + 1 for i in range(len(pca.explained_variance_ratio_))], 100 * pca.explained_variance_ratio_.cumsum(), 'b-')\n",
    "ax.axvline(2, color='green')\n",
    "ax.axvline(10, color='yellow')\n",
    "ax.axvline(20, color='red')\n",
    "ax.set_xlabel('Componentes')\n",
    "ax.set_ylabel('% da variância explicada')\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Vamos tentar utilizar menos componentes?\n",
    "\n",
    " Normalmente, buscamos a quantidade de componentes que explicam entre 95-99% da variância dos dados (experiência própria). O restante normalmente está capturando variações de ruído ou outros aspectos que não nos interessam. Nesse caso empíricamente escolhi os 10 primeiros componentes (um pouco exagerado até, talvez). Os resultados foram bem melhores para a RF. Decidi adicionar um modelo linear e aumentar para 15 e depois 20 componentes. Os resultados surpreenderam.\n",
    "\n",
    " Sugiro testarem outros valores e avaliarem os resultados obtidos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20)\n",
    "\n",
    "X_tr_pca = pca.fit_transform(X_tr_pca)\n",
    "X_ts_pca = pca.transform(X_ts_pca)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 20)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_pca.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Voltando à RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE da RF: 0.7463076722491517\n",
      "RRMSE da RF: 0.790250016555675\n"
     ]
    }
   ],
   "source": [
    "dt_pca = DecisionTreeRegressor(max_depth=4)\n",
    "dt_pca.fit(X_tr_pca, y_tr)\n",
    "preds_rf = dt_pca.predict(X_ts_pca)\n",
    "preds_rf = scaler_y.inverse_transform(preds_rf.reshape(-1, 1))[:, 0]\n",
    "\n",
    "print('RMSE da RF:', RMSE(y_ts, preds_rf))\n",
    "print('RRMSE da RF:', RRMSE(y_ts, preds_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### \"Avacalhation\" time\n",
    "\n",
    " Vamos treinar uma simples regressão linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE da LR: 0.37561323876721775\n",
      "RRMSE da LR: 0.3977292855001388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_tr_pca, y_tr)\n",
    "\n",
    "preds_lr = lr.predict(X_ts_pca)\n",
    "preds_lr = scaler_y.inverse_transform(preds_lr.reshape(-1, 1))[:, 0]\n",
    "print('RMSE da LR:', RMSE(y_ts, preds_lr))\n",
    "print('RRMSE da LR:', RRMSE(y_ts, preds_lr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.36556543e-03, -1.44606694e-02,  2.40548681e-02, -7.01287594e-02,\n",
       "        1.79961690e-01, -1.15146765e-02, -3.59760056e-01, -2.51777122e-02,\n",
       "        6.03110953e-01,  5.12555987e-01,  3.48266724e-01, -1.07716796e+00,\n",
       "       -1.69779481e-01, -1.16358924e+00, -9.46780280e-01,  4.63364261e-01,\n",
       "        1.52624574e+00,  2.57797153e-01, -8.25794923e-01,  1.96831398e+00])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Considerações finais\n",
    "\n",
    " - Problema linear! $\\rightarrow$ viés de aprendizado do algoritmo não adequado ao problema, dadas as características do dataset.\n",
    "     * Como traçar uma reta usando retângulos? :D\n",
    "\n",
    " A utilização de pré-processamento com PCA foi essencial para diminuir o erro preditivo!\n",
    " - Os modelos finais conseguiram melhor e muito o desempenho do baseline\n",
    "     * Importância da utilização de métricas adequadas para avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
